# 失败的尝试
## 参数调整|更换attention实现方式|添加Mlp层

调整参数 激活层，hidden_size,dropout **失败** 最佳结果<74

feature直接堆叠 **失败**  最佳结果<74

更换attention实现方式 原始GAT实现，用deepwalk的实现  **失败**  最佳结果<74

用deepwalk的向量进行拼接  **失败**  最佳结果<74

添加全连接  **失败**  最佳结果<74

总结经验： attention的操作是一种聚合操作，需要和周围的邻居按照比例进行加权。在进行**加**的操作之前，不能添加norm或act_layer，防止**不同表意**的特征混合。
# 对FSGNN分析
FSGNN的模型概要

1. feature预处理：聚合操作 each_layer=features.dot(khop_adj)
2. 降维 ：nn.linear(feature,nhid=64) for each layer 
3. 归一化: f.normalize(nhid) for each layer
4. 对layer选择（没什么用）：multiply a learnable weight for each layer
5. relu (concat each layer )
6. 分类器 ：fc
# 不应该把聚合的信息输入，而应该把我们的模型用来做聚合

把上面的1，2， 换成 
1. 线性降维 
2. Att ( neigborAtt (for each khop node ) )由于邻居多，这里用采样

提升 **76.6886, 1.35**

# 注意到FSGNN同时考虑到了：self-loop和非self-loop

改进：同时在  在att的时候把自己features的mask掉，仿照没有self-loop。

提升 ->77

# 有效提升方案 self-punishment + 平滑

注意到过拟合严重

self-punishment: 在attention阶段，自己权重乘一个常数，减少自身信息摄入。

把每一个layer降维的结果，有self-loop和没有self-loop的分别相加。

78.6623 = acc(FSGNN)+0.5

但时间实在太长

# 之后我又优化一下FSGNN 达到了acc=79.5

这里抛弃了有self-loop的情况，为了去重，实验证明明显的有效
```python
    list_mat = []
    list_mat.append(features)
    no_loop_mat = features

    for ii in range(args.layer):
        no_loop_mat = torch.spmm(adj, no_loop_mat)
        # loop_mat = torch.spmm(adj_i, loop_mat)
        list_mat.append(no_loop_mat)
        # list_mat.append(loop_mat)
```

方案，对降维后的向量 简单的加入maxpooling 

也对我们的模型尝试了maxpooling   78.0482, 0.96

在cora数据集，acc<85
# 关于Bert的尝试

Beit的模型概要

1. images->patch_embeding
2. image ->visual token  这一步是把image的每一个patch映射到一个数，这一步是模仿nlp的每一个词都有一个onehot编码,然后再映射回image，寻找最小损失的映射
3. 把image的部分patchmask掉，以完整的visual_token为目标训练transformer，这样把训练的数据集扩大了几倍
4. 用训练好的transformer拼接上分类器训练

映射到图学习的困难

1. patch_embeding 
2. 数据集太小

图学习目前没有transformer，是因为图学习非features相当于只有一个patch，把部分的features mask掉是不可取的，因为图学习的feature不存在序列性。

但是可以用FSGNN的使用adj不断用作为patch，每一个layer相当于一个patch。

谷歌做bert的实验使用了8台GPU跑了几天，发现在百万级别的数据集的情况能超过Vit

# 目前的进度

如果FSGNN的使用adj不断用作为patch，忽略了节点的邻居之间的特性。但是GAT所用时间长，即使用GAT和FSGNN的区别并不大。

目前阶段暂时使用FSGNN的方法进行探索，之前验证了pooling操作是有效的。在chameleon数据集average-pooling几乎没用，maxpooling有78.2->79.5的提升。

在patch_embeding的阶段：已经证明不行的：
1. 用GAT训练好的模型的attention替换adj
2. 用GAT一边训练一遍聚合多层的邻居节点特征。
3. postion—embeding
   
还有的idea:
1. 用和原始的adj加上根据图形结构得出的偏置，
2. 用多层GAT的每一层的输出作为embeding。**最有戏**
3. 对邻居进行不等概率的采样。比如，节点有 3个1hop邻居，7个2hop的邻居。考虑到邻居少的节点，我们先对每一个邻居加一个空节点作为邻居，然后进行n次采样，每次采样5个邻居，距离近的采样概率高。

在得到embeding之后：已经尝试的：
1. 对patch进行attention，失败，这个可能是由于没有加入残差链接，存疑
   
还有的ideal：
1. transformer 

   


1. skip-connection
2. 扩展数据集
3. GAE

