完成的任务：
1. 浏览graph领域的论文
2. 实现ADSF，更改数据集（计算）
3. 进行两个简单的构思
4. 关于之前边多，干扰点少的结论，还没有具体尝试 `Understanding Attention and Generalization in Graph Neural Networks` more robust to larger and noisy graphs
1.attention score 类似一种无监督学习 
each node has a graph structural embeding -> r_i
横向对比 ：

using r_i to calculate the attention score : ADSF 用的是**常量**，是RWR->calculate intersaction。GEom-GCN是计算RW->word2vec

用类似GEom的方法把图片信息转化为低纬的ri，分别是随机游走和word2vec(单层神经网络)，然后用ri计算attention score，用attention score乘可学习的参数和原来的attention score加权。

2.改一下上面的公式，延续之前自适应的attention的思路。通过hi计算attention score。e_ij=Att( concat(hi,hj) )。`可以考虑用GATv2，就是初始GAT交换顺序之后的公式`

然后对每一个 hi * W1 之后非线性化，得到ai。 对每一个ei向量乘上ai 再激活，得到计算得到的attention score。

注意到之前的一些有意义的尝试：

1. 通过在attention层之后添加一些全连接层，增强模型聚合信息的能力。
2. shreshold
遇到的问题
1. rwr的公式存疑 extension://cdonnmffkdaoajfknoeeecmchibpmkmg/assets/pdf/web/viewer.html?file=http%3A%2F%2Fwww2.cs.uh.edu%2F~ceick%2F7363%2FPapers%2Ftong.pdf
   
   
