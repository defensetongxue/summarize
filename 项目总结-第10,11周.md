## 数据集扩展
cora 85(mix-hop)

cite 73.8

cham 79.3

squirrel 70.6532, 1.79

pumb 85（没有mixhop，有一定提升空间）

Texas 64.5946, **9.4**(很不稳定，有很大提升空间)

62.9412, 4.68 (很不稳定，有很大提升空间)
ogb(待跑)
## 做的有意义的尝试
发现，不论是DGAT，还是GAT，attention的取值都非常的接近。只是由于，GAT是基于多数表决进行的。在一次投票中，我们对节点自身和其邻居是一视同仁的，在梯度传播的时候，都会往相同的梯度传递。而GAT的时候并不是基于节点的相似度分配权重，而是基于节点的**重要程度**分配的。节点的重要程度被定义为特征的一维的编码。

具体来说
GAT：
1. $H=XW$ 
2. $W_1=HA_1,W2=HA_2$
3. $Att=W_1+W_2.T$


打印编码，发现W_1和W_2分布在-1到7之间，因为本质上，是F的编码，有边的节点会有一个相同的梯度导致趋同。所以att是相同的。在一开始的时候，因为本身特征稀疏，降维之后其实并不能有清晰的表达，所以在最开始的时候，att就不具备找到相似性的能力。而在CV中，从patch_embeding之处的时候，就本身具有一定的表示能力。所以，Graph领域的初始化方式很重要。

另外值得一提的是，我探究了一下这个W_1和W_2是否能找到一些经验性的排名的能力，也就是比如W_1大的节点有一些特性。但没有成功。比如，是否训练集的W_1高，或者变的数量多，或者同类变多的高。

比如有五个节点 1 2 3 4 5 ， 1 2 3 一个邻域， 3 4 5 一个邻域，一开始的时候 1 2 3 的一维的特征比较低，3 4 5 比较高。在之后的学习中，3 会逐渐在前一个邻域变得越来越“重要”，在后一个邻域变得“越来越不重要”这个显然是不合理的。

总结：Att失效的原因，向量稀疏，在尚未训练之时，被随机矩阵降维，使得一开始的时候，使得不知道一个图什么节点是重要的。之后学习的时候，因为梯度相同，只能学出，有边的节点重要性差不多。想要解决attention失效的问题，需要找到一个预处理，或者预训练的方式，就好像Nlp里面用word2vec代替了one——hot编码一样

F,A

### 梯度抛弃

训练过程中，以一定的比例抛弃节点邻居的梯度。具体来说，就是在梯度传递的时候，暂时性的把每个节点的邻居特征当做常量，不对邻居的判断结果惩罚。

目的：使得每个节点能够初步的认识自己，再参加attention、

恒定比例或者一开始比例高，之后逐渐降低。

失败（观测有微弱的提升，但实际效果存疑）

### 寻找模型的可解释性

用Nlp的方法来解释我们的模型。我们的模型其实类似于Nlp的transformer

我的认为，一个节点极其邻域的特征能够帮我们判断正确的节点。在这个模型里，每一个节点实际上相当于一个词。一个节点的邻域相当于一个句子，我们对一个个句子进行分类。

具体操作就像Nlp的transformer一样。先对词之间attention，然后用一个clstoken综合所有的词。

我们的position_embeding是采用不同的方法对不同距离的邻居降维，同一个距离的邻居有相同的position。

cls_token是有这个节点本身的向量直接生成。

我也在尽可能不影响我们模型的效果的情况下，把我们的模型改的更像Nlp的transfor。

### 激活函数的策略

对于邻居激活的时候不能使用relu


### 我们模型目前敲定的版本

1. $H=XW$
2. $Neigbor=\text{采样}(H)$
3. $Neigbor=Mlp(Attention(Neigbors))$这是完全模仿一个transfomer
4. $cls_token=linear(h)$
5. $neighbors=cat(cls_token,neigbors)$$
6. $res=Attention(neigbors)[0]$
基本相当于2层的transformer，在nlp中使用

### 之后可能的修改
1. batch_norm
2. 参数调整

### 采样
采样数量 一阶150（几乎所有都考虑在内） 二阶 100如果比较少，会效果不好。采样是一开始采好就不东了，但是会采4个头，就是多头attention，每个头采样不同。但规则相同。

从观察来看，目前大多数节点的度数是小于这个数的。度数都是在5个以内，只有极少数的超级节点的度数会超过这个数目

考虑过得：
1. 训练的时候采样的节点少，测试的时候多。
2. 每次都重新采样
3. 测试的时候，尽量采样训练集的节点
4. 调整了采样的数目

## 问题域的修改
一开始不能够获取整张图像，只能获取训练集对应的部分，在测试和训练的时候，才能获取相应部分的图像。

但是在这个各方面，我也做实验发现，在cora数据集上，GAT依然和GCN没什么区别。

Att=A（WX_1)+A(WX_2）

embeding lookup
16 

10086->表

【】-> nn.linear ->[2000,8]->[8]-[64]

ogb-  GPU


